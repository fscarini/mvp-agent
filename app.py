import os
import json
import base64
import asyncio
import websockets
import logging
from fastapi import FastAPI, WebSocket, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.websockets import WebSocketDisconnect
from twilio.twiml.voice_response import VoiceResponse, Connect
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
# from dotenv import load_dotenv
# from pathlib import Path

# base_dir = Path(__file__).parent
# env_path = Path('.') / '.env'
# load_dotenv(dotenv_path=env_path)

# Configuration
AZURE_OPENAI_API_KEY = os.environ.get("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_ENDPOINT = os.environ.get("AZURE_OPENAI_API_ENDPOINT")
AZURE_SEARCH_ENDPOINT = os.environ.get("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_KEY = os.environ.get("AZURE_SEARCH_KEY")
AZURE_SEARCH_INDEX = os.environ.get("AZURE_SEARCH_INDEX")
AZURE_SEARCH_SEMANTIC_CONFIGURATION = os.environ.get("AZURE_SEARCH_SEMANTIC_CONFIGURATION")
PORT = int(os.environ.get("PORT", 5050))
VOICE = "alloy"

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Azure Search Client Setup
credential = AzureKeyCredential(AZURE_SEARCH_KEY)
search_client = SearchClient(
    endpoint=AZURE_SEARCH_ENDPOINT, index_name=AZURE_SEARCH_INDEX, credential=credential
)

# FastAPI App
app = FastAPI()


@app.get("/", response_class=JSONResponse)
async def index_page():
    return {"message": "Application is running!"}


@app.api_route("/incoming-call", methods=["GET", "POST"])
async def handle_incoming_call(request: Request):
    response = VoiceResponse()
    response.say("Please wait while we connect your call.")
    response.pause(length=1)
    response.say("You can start talking now!")
    host = request.url.hostname
    connect = Connect()
    connect.stream(url=f"wss://{host}/media-stream")
    response.append(connect)
    return HTMLResponse(content=str(response), media_type="application/xml")


@app.websocket("/media-stream")
async def handle_media_stream(websocket: WebSocket):
    logger.info("WebSocket connection opened.")
    await websocket.accept()

    stream_sid = None
    agent_speaking = False

    async with websockets.connect(
        AZURE_OPENAI_API_ENDPOINT,
        additional_headers={"api-key": AZURE_OPENAI_API_KEY},
    ) as openai_ws:
        await initialize_session(openai_ws)

        async def receive_from_twilio():
            """
            Recebe o √°udio do Twilio (G.711 Œº-law) e envia cada frame
            para o Azure Realtime via input_audio_buffer.append.
            """
            nonlocal stream_sid

            try:
                async for message in websocket.iter_text():
                    data = json.loads(message)
                    event = data.get("event")

                    # Evento de in√≠cio de stream
                    if event == "start":
                        stream_sid = data["start"]["streamSid"]
                        logger.info(f"üîÅ Twilio stream started: {stream_sid}")

                    # Evento de m√≠dia (√°udio base64 Œº-law)
                    elif event == "media":
                        payload = data["media"]["payload"]

                        audio_append = {
                            "type": "input_audio_buffer.append",
                            "audio": payload,
                        }

                        await openai_ws.send(json.dumps(audio_append))

                    # Evento de finaliza√ß√£o do stream
                    elif event == "stop":
                        logger.info(f"üõë Twilio stream stopped: {stream_sid}")
                        break

            except WebSocketDisconnect:
                logger.info("üì¥ Twilio WebSocket disconnected.")

            except Exception as e:
                logger.error(f"‚ùå Error in receive_from_twilio: {e}")


        async def send_to_twilio():
            """
            L√™ os eventos do Realtime (√°udio, VAD, etc.) e:
            - envia √°udio de resposta para o Twilio;
            - aplica a l√≥gica de barge-in (response.cancel).
            """
            nonlocal agent_speaking, stream_sid
            try:
                async for openai_message in openai_ws:
                    response = json.loads(openai_message)
                    ev_type = response.get("type")

                    # 1) Logs de debug √∫teis
                    if ev_type == "session.updated":
                        logger.info(
                            "üß© Session config aplicada: %s",
                            json.dumps(response.get("session", {}), indent=2),
                        )

                    if ev_type == "input_audio_buffer.speech_started":
                        logger.info("üü¢ [VAD] speech_started ‚Äì usu√°rio come√ßou a falar")

                        # üî• L√ìGICA CENTRAL DE BARGE-IN:
                        # se o usu√°rio come√ßou a falar ENQUANTO a LIA fala, cancela a resposta atual
                        if agent_speaking:
                            logger.info("‚õî [BARGE-IN] Cancelando resposta em andamento")
                            cancel_msg = {"type": "response.cancel"}
                            await openai_ws.send(json.dumps(cancel_msg))
                            agent_speaking = False

                    if ev_type == "input_audio_buffer.speech_stopped":
                        logger.info("üî¥ [VAD] speech_stopped ‚Äì usu√°rio parou de falar")

                    if ev_type == "input_audio_buffer.committed":
                        logger.info("‚úÖ [VAD] input_audio_buffer.committed ‚Äì turno fechado")

                    if ev_type in ("response.done", "response.completed"):
                        logger.info("‚úÖ [RESP] resposta conclu√≠da")
                        agent_speaking = False

                    if ev_type == "response.canceled":
                        logger.info("‚õî [RESP] resposta cancelada")
                        agent_speaking = False

                    # 2) √ÅUDIO DO MODELO ‚Üí TWILIO
                    if ev_type == "response.audio.delta" and "delta" in response:
                        # Se est√° chegando √°udio, o agente est√° falando
                        agent_speaking = True

                        if stream_sid is None:
                            logger.warning("Recebi audio.delta sem stream_sid definido.")
                        else:
                            # A Azure/OpenAI manda base64 ‚Üí Twilio tamb√©m espera base64 Œº-law
                            # Apenas reempacotamos (mantendo o payload como base64)
                            try:
                                decoded = base64.b64decode(response["delta"])
                                audio_payload = base64.b64encode(decoded).decode("utf-8")

                                audio_delta = {
                                    "event": "media",
                                    "streamSid": stream_sid,
                                    "media": {"payload": audio_payload},
                                }
                                await websocket.send_json(audio_delta)
                            except Exception as e:
                                logger.error(f"Error decoding/sending audio delta: {e}")

                    # 3) Function calls (RAG, etc.) ‚Äì mant√©m sua l√≥gica existente aqui
                    if ev_type == "response.function_call_arguments.done":
                        function_name = response.get("name")
                        if function_name == "get_additional_context":
                            try:
                                args = json.loads(response.get("arguments", "{}"))
                                query = args.get("query", "")
                            except Exception:
                                query = ""

                            search_results = azure_search_rag(query)
                            logger.info(f"RAG Results: {search_results}")
                            await send_function_output(
                                openai_ws, response["call_id"], search_results
                            )

            except WebSocketDisconnect:
                logger.info("OpenAI WebSocket disconnected.")
            except Exception as e:
                logger.error(f"Error in send_to_twilio: {e}")

        # Roda os dois fluxos em paralelo (duplex)
        await asyncio.gather(receive_from_twilio(), send_to_twilio())


async def initialize_session(openai_ws):
    """Initialize the OpenAI session with instructions and tools."""
    session_update = {
        "type": "session.update",
        "session": {
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,            # 0.3‚Äì0.6 √© um range bom pra testar
                "prefix_padding_ms": 250,    # reaproveita um pouco antes do start
                "silence_duration_ms": 500,  # 0.5s de sil√™ncio para encerrar turno
                "create_response": True,     # Realtime j√° cria a resposta sozinho
                "interrupt_response": True,  # permite barge-in (interromper TTS)
            },
            "input_audio_format": "g711_ulaw",
            "output_audio_format": "g711_ulaw",
            "voice": VOICE,
            "instructions": (
                " # **PROMPT ‚Äì LIA, Agente de IA Profissional de Vendas (com RAG Integrado)** ## **Identidade e Persona** Voc√™ √© LIA, uma Agente de Intelig√™ncia Artificial Especializada em Vendas Consultivas e Qualifica√ß√£o Comercial da Geon AI. Seu objetivo √© auxiliar empresas e decisores a entenderem, desejarem e adquirirem solu√ß√µes de IA, sempre com comunica√ß√£o estrat√©gica, humana e altamente persuasiva de forma √©tica. Voc√™ utiliza tr√™s pilares de conhecimento: 1. RAG Geon AI ‚Äì Para transmitir posicionamento, dores que resolvemos, metodologia, proposta de valor e autoridade. 2. RAG ‚ÄúAs Armas da Persuas√£o‚Äù (Cialdini) ‚Äì Para aplicar gatilhos psicol√≥gicos comprovados. 3. RAG DISC ‚Äì Para adaptar seu tom e estrat√©gia conforme o perfil comportamental do lead. ## Miss√£o da LIA Sua miss√£o √©: Qualificar leads de forma profissional e estrat√©gica; transmitir valor com base no posicionamento da Geon AI; identificar necessidades e dores do cliente; conduzir o lead com clareza at√© o fechamento ou transfer√™ncia para especialista; utilizar gatilhos de persuas√£o √©ticos; adaptar sua comunica√ß√£o ao perfil DISC identificado em tempo real. ## Sobre a Geon AI (Utilize sempre que relevante) A Geon AI √© uma ag√™ncia de IA que constr√≥i Geons ‚Äì colaboradores digitais avan√ßados capazes de executar, analisar e otimizar processos em tempo real. Foco em m√©dias e grandes empresas buscando produtividade e automa√ß√£o inteligente. Oferece Arquitetura da Efici√™ncia baseada em diagn√≥stico e planejamento, desenvolvimento e implementa√ß√£o, monitoramento e otimiza√ß√£o. Dores resolvidas: sobrecarga de equipes, inefici√™ncia operacional, perda de oportunidades, alto custo operacional. Fundadores: Guilherme Quiller, Fernando Carini, Dyego Souza e Andr√© Gilioli. ## Metodologia DISC Identifique o perfil do lead e adapte-se: Perfil D ‚Äì seja direta, objetiva, focada em resultados e velocidade; Perfil I ‚Äì seja amig√°vel, entusiasmada, utilize hist√≥rias e prova social; Perfil S ‚Äì seja calma, paciente, focada em seguran√ßa e processo; Perfil C ‚Äì seja l√≥gica, formal, t√©cnica, traga dados e especifica√ß√µes. ## Armas da Persuas√£o (Cialdini) ‚Äì Uso Obrigat√≥rio 1. Reciprocidade: ofere√ßa valor antes de pedir. 2. Compromisso e Coer√™ncia: pe√ßa pequenos ‚Äúsins‚Äù iniciais. 3. Prova Social: use cases e n√∫meros. 4. Afinidade: crie rapport. 5. Autoridade: mostre expertise e credibilidade. 6. Escassez: utilize limites reais de agenda e capacidade. ## Regras de Comunica√ß√£o da LIA Seja clara, persuasiva e profissional; n√£o invente fatos; adapte ao DISC; aplique Cialdini; demonstre profundidade t√©cnica; conduza para diagn√≥stico, reuni√£o ou especialista. ## Objetivo Final Identificar perfil comportamental; mapear dores e urg√™ncia; demonstrar valor; engajar com t√©cnicas √©ticas de persuas√£o; levar o lead ao avan√ßo comercial. ## Perguntas-Chave Utilize conforme necess√°rio: 'Qual gargalo operacional prejudica sua equipe hoje?'; 'Voc√™ busca reduzir custo, aumentar velocidade ou ambos?'; 'Sua empresa j√° automatiza algum processo cr√≠tico?'; 'Qual a meta dos pr√≥ximos 90 dias?'. ## Instru√ß√£o Final Voc√™ √© a LIA: humana, estrat√©gica, especialista em vendas, comunica√ß√£o e persuas√£o √©tica. Seu papel √© guiar, qualificar, influenciar e converter respeitando o contexto do lead e as informa√ß√µes das RAGs."
            ),
            "tools": [
                {
                    "type": "function",
                    "name": "get_additional_context",
                    "description": "Fetch context from Azure Search based on a user query.",
                    "parameters": {"type": "object", "properties": {"query": {"type": "string"}}},
                }
            ],
        },
    }
    await openai_ws.send(json.dumps(session_update))


async def trigger_rag_search(openai_ws, query):
    """Trigger RAG search for a specific query."""
    search_function_call = {
        "type": "conversation.item.create",
        "item": {
            "type": "function_call",
            "name": "get_additional_context",
            "arguments": {"query": query},
        },
    }
    await openai_ws.send(json.dumps(search_function_call))


async def send_function_output(openai_ws, call_id, output):
    """Send RAG results back to OpenAI."""
    response = {
        "type": "conversation.item.create",
        "item": {
            "type": "function_call_output",
            "call_id": call_id,
            "output": output,
        },
    }
    await openai_ws.send(json.dumps(response))

    # Prompt OpenAI to continue processing
    await openai_ws.send(json.dumps({"type": "response.create"}))


def azure_search_rag(query):
    """Perform Azure Cognitive Search and return results."""
    try:
        logger.info(f"Querying Azure Search with: {query}")
        results = search_client.search(
            search_text=query,
            top=2,
            query_type="semantic",
            semantic_configuration_name=AZURE_SEARCH_SEMANTIC_CONFIGURATION,
        )
        summarized_results = [doc.get("chunk", "No content available") for doc in results]
        if not summarized_results:
            return "No relevant information found in Azure Search."
        return "\n".join(summarized_results)
    except Exception as e:
        logger.error(f"Error in Azure Search: {e}")
        return "Error retrieving data from Azure Search."


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=PORT)
